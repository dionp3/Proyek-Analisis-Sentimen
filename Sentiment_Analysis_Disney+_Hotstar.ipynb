{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nama : Dion Prayoga"
      ],
      "metadata": {
        "id": "Vl8EkyeNZjb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyek Analisis Sentimen Disney+ Hotstar\n",
        "\n",
        "**Submission Pertama** dari course **Belajar Pengembangan Machine Learning (Dicoding)**.  \n",
        "\n",
        "## Deskripsi Proyek\n",
        "Proyek ini berfokus pada **analisis sentimen** terhadap ulasan pengguna aplikasi **Disney+ Hotstar** yang diperoleh dari **Google Play Store**. Proses analisis mencakup:\n",
        "\n",
        "- **Web Scraping** untuk mengambil data ulasan.\n",
        "- **Pra-pemrosesan Data** untuk mempersiapkan data untuk analisis.\n",
        "- **Klasifikasi Sentimen** menggunakan teknik **Machine Learning**.\n",
        "\n",
        "## Pelatihan Model\n",
        "Tiga model digunakan dalam proyek ini:\n",
        "1. **SVM dengan TF-IDF**: Menggunakan model Support Vector Machine (SVM) dengan representasi fitur berbasis TF-IDF untuk memproses teks.\n",
        "2. **Random Forest dengan TF-IDF**: Model Random Forest yang juga menggunakan representasi fitur berbasis TF-IDF.\n",
        "3. **Deep Learning dengan LSTM**: Model jaringan saraf berbasis LSTM untuk memproses teks.\n",
        "\n",
        "## Hasil\n",
        "Setelah melatih ketiga model, hasil evaluasi menunjukkan bahwa model terbaik dipilih berdasarkan akurasi tertinggi. Perbandingan antara label aktual dan prediksi untuk model dengan kinerja terbaik ditampilkan untuk menunjukkan bagaimana model memprediksi sentimen dalam ulasan."
      ],
      "metadata": {
        "id": "rDDvLwUWwXx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📚 Import Library"
      ],
      "metadata": {
        "id": "8Qq6v7a1wTxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from collections import Counter\n",
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "fH8I0WtxmW4F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📥 Membaca Dataset"
      ],
      "metadata": {
        "id": "8n_TH-n2zIJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7kILLpthOToJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a04565-e4ee-4557-ef94-b8817ed08049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah baris dan kolom:\n",
            "(20000, 11)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('reviews_disneyhotstar.csv')\n",
        "\n",
        "print(\"Jumlah baris dan kolom:\")\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧾 Memuat dan Mengecek Informasi Dataset"
      ],
      "metadata": {
        "id": "KmUGvO17g_rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('reviews_disneyhotstar.csv')\n",
        "\n",
        "print(\"\\nInformasi kolom:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6g3vjqAmfhV",
        "outputId": "eb77c28d-39af-4d41-b966-4d51828a2ada"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Informasi kolom:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   reviewId              20000 non-null  object\n",
            " 1   userName              20000 non-null  object\n",
            " 2   userImage             20000 non-null  object\n",
            " 3   content               20000 non-null  object\n",
            " 4   score                 20000 non-null  int64 \n",
            " 5   thumbsUpCount         20000 non-null  int64 \n",
            " 6   reviewCreatedVersion  13697 non-null  object\n",
            " 7   at                    20000 non-null  object\n",
            " 8   replyContent          4729 non-null   object\n",
            " 9   repliedAt             4729 non-null   object\n",
            " 10  appVersion            13697 non-null  object\n",
            "dtypes: int64(2), object(9)\n",
            "memory usage: 1.7+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👀 Menampilkan 5 Baris Pertama Dataset"
      ],
      "metadata": {
        "id": "polwdOef0WWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('reviews_disneyhotstar.csv')\n",
        "\n",
        "print(\"\\n5 baris pertama dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "Oph2c1f-nhwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed0cd55-980e-428f-b20f-1ca48d98d0ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5 baris pertama dataset:\n",
            "                               reviewId         userName  \\\n",
            "0  395f4a25-241d-411c-9c3b-51a22499ea41  Pengguna Google   \n",
            "1  e3ae832a-6ffe-4e66-b081-b37e364ce2a4  Pengguna Google   \n",
            "2  d99927ec-1f07-4af8-b4da-79880797472e  Pengguna Google   \n",
            "3  6b3eca7c-f203-4c87-89d6-12244e0b7646  Pengguna Google   \n",
            "4  66cfef11-fdbf-4305-b7b5-ba80214c175a  Pengguna Google   \n",
            "\n",
            "                                           userImage  \\\n",
            "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "\n",
            "                                             content  score  thumbsUpCount  \\\n",
            "0           di hp ada suaranya, di tv gaada suaranya      2              0   \n",
            "1  lebih baik gratis dari pada susah berlangganan 😑😑      1              0   \n",
            "2          Jelek bgt nyesel dowlod jangan dowlod ini      1              0   \n",
            "3  kenapa lagi ente bang disney+, mau nonton seri...      1             38   \n",
            "4  sumpah gw nonton mata gw sakit udah setting 10...      1              0   \n",
            "\n",
            "  reviewCreatedVersion                   at  \\\n",
            "0                  NaN  2025-04-20 14:05:45   \n",
            "1           25.04.07.1  2025-04-20 10:18:36   \n",
            "2                  NaN  2025-04-20 09:12:16   \n",
            "3           25.04.07.1  2025-04-20 05:30:52   \n",
            "4                  NaN  2025-04-20 05:18:33   \n",
            "\n",
            "                                        replyContent            repliedAt  \\\n",
            "0  Hai Salwa, mohon maaf atas ketidaknyamanannya....  2025-04-21 09:53:27   \n",
            "1  Hai Ahmad, sebagai informasi Disney+ Hotstar m...  2025-04-20 10:56:13   \n",
            "2                                                NaN                  NaN   \n",
            "3                                                NaN                  NaN   \n",
            "4  Hai! Mohon maaf atas ketidaknyamannya. Mohon k...  2025-04-20 09:35:13   \n",
            "\n",
            "   appVersion  \n",
            "0         NaN  \n",
            "1  25.04.07.1  \n",
            "2         NaN  \n",
            "3  25.04.07.1  \n",
            "4         NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧹 Pembersihan Data: Menghapus Nilai Null pada Kolom 'userName'"
      ],
      "metadata": {
        "id": "PSrr4s8q0Yn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = df.dropna(subset=['userName'])\n",
        "print(df_cleaned.isnull().sum())\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ovCth1Dmolx",
        "outputId": "1e439994-ecac-4f82-9afa-b791db12cde7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reviewId                    0\n",
            "userName                    0\n",
            "userImage                   0\n",
            "content                     0\n",
            "score                       0\n",
            "thumbsUpCount               0\n",
            "reviewCreatedVersion     6303\n",
            "at                          0\n",
            "replyContent            15271\n",
            "repliedAt               15271\n",
            "appVersion               6303\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧼 Pembersihan Teks: Membersihkan Konten Ulasan"
      ],
      "metadata": {
        "id": "Grv8d5k_0l2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text\n",
        "\n",
        "df['cleaned_content'] = df['content'].apply(clean_text)"
      ],
      "metadata": {
        "id": "O19jvY_6mp7p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Klasifikasi Sentimen: Menentukan Sentimen Ulasan"
      ],
      "metadata": {
        "id": "GxOTv-4t0o7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(text):\n",
        "    from textblob import TextBlob\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 'positif'\n",
        "    elif polarity < 0:\n",
        "        return 'negatif'\n",
        "    else:\n",
        "        return 'netral'\n",
        "\n",
        "df['label'] = df['cleaned_content'].apply(get_sentiment)"
      ],
      "metadata": {
        "id": "Q4eofWIMmsw-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔀 Membagi Data: Pembagian Data Latih dan Uji"
      ],
      "metadata": {
        "id": "XiMIey0E0rmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = LabelEncoder().fit_transform(df['label'])\n",
        "X = df['cleaned_content']\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "BB8677wZmvvD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Pemrosesan Fitur dan Penanganan Kelas Tidak Seimbang"
      ],
      "metadata": {
        "id": "F8-cB9IA0yWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_raw)\n",
        "X_test_tfidf = vectorizer.transform(X_test_raw)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf_smote, y_train_smote = smote.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Distribusi label setelah SMOTE:\", Counter(y_train_smote))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yP6vogTmyxw",
        "outputId": "84d58835-8425-4d9c-9125-1741f32f8ce4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribusi label setelah SMOTE: Counter({np.int64(1): 13957, np.int64(2): 13957, np.int64(0): 13957})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚙️ Pelatihan dan Evaluasi Model SVM"
      ],
      "metadata": {
        "id": "4GhyTbwR0zGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear', random_state=42)\n",
        "svm.fit(X_train_tfidf_smote, y_train_smote)\n",
        "y_pred_svm = svm.predict(X_test_tfidf)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"\\nEvaluasi Model SVM:\")\n",
        "print(f\"Accuracy: {accuracy_svm}\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=['negatif', 'netral', 'positif']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luzPaU1jm0gR",
        "outputId": "d68af363-9053-442a-d0a7-d7b27cb617e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluasi Model SVM:\n",
            "Accuracy: 0.981\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.86      0.80      0.83       128\n",
            "      netral       0.99      1.00      0.99      3489\n",
            "     positif       0.97      0.91      0.94       383\n",
            "\n",
            "    accuracy                           0.98      4000\n",
            "   macro avg       0.94      0.90      0.92      4000\n",
            "weighted avg       0.98      0.98      0.98      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Support Vector Machine (SVM) menunjukkan kinerja yang sangat baik dengan akurasi mencapai 98.1%, yang berarti model dapat mengklasifikasikan hampir 98 dari 100 ulasan dengan benar. Untuk kategori \"netral\", model memiliki precision dan recall hampir sempurna (0.99 dan 1.00), sementara untuk kategori \"positif\" juga sangat baik dengan F1-Score 0.94. Namun, untuk kategori \"negatif\", model sedikit lebih rendah dengan recall 0.80, yang menunjukkan bahwa beberapa ulasan negatif tidak terdeteksi. Meskipun demikian, model secara keseluruhan menunjukkan hasil yang solid dengan precision, recall, dan F1-Score yang tinggi, terutama pada kategori dengan jumlah data yang lebih besar (netral)."
      ],
      "metadata": {
        "id": "zoaHlQgg1X0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚙️ Pelatihan dan Evaluasi Model Random Forest"
      ],
      "metadata": {
        "id": "L1HwcqSO07jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train_tfidf_smote, y_train_smote)\n",
        "y_pred_rf = rf.predict(X_test_tfidf)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"\\nEvaluasi Model Random Forest:\")\n",
        "print(f\"Accuracy: {accuracy_rf}\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=['negatif', 'netral', 'positif']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kRhCn4xnL4R",
        "outputId": "18a0ce51-ec15-44c8-e6c3-19a5314f2dc9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluasi Model Random Forest:\n",
            "Accuracy: 0.9525\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.93      0.58      0.71       128\n",
            "      netral       0.95      1.00      0.97      3489\n",
            "     positif       0.95      0.68      0.79       383\n",
            "\n",
            "    accuracy                           0.95      4000\n",
            "   macro avg       0.94      0.75      0.83      4000\n",
            "weighted avg       0.95      0.95      0.95      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Random Forest memberikan akurasi 95.25%, yang menunjukkan kinerja yang cukup baik dalam mengklasifikasikan ulasan. Precision dan recall untuk kategori \"netral\" sangat baik dengan precision 0.95 dan recall 1.00, sementara untuk kategori \"positif\" dan \"negatif\" hasilnya sedikit lebih rendah. Kategori \"negatif\" memiliki recall yang rendah (0.58), menunjukkan bahwa banyak ulasan negatif yang tidak terdeteksi dengan baik, meskipun precision-nya tinggi (0.93). Demikian pula, kategori \"positif\" memiliki recall yang lebih rendah (0.68), namun precision-nya tetap tinggi (0.95). Secara keseluruhan, meskipun ada kesulitan dalam mengklasifikasikan ulasan negatif dan positif, model ini tetap efektif dengan nilai F1-Score yang cukup baik dan akurasi tinggi secara keseluruhan."
      ],
      "metadata": {
        "id": "F6hbamvw1bTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧑‍💻 Tokenisasi dan Padding untuk Data Teks"
      ],
      "metadata": {
        "id": "vmtgXAAE08sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 10000\n",
        "max_len = 100\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train_raw)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_raw)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test_raw)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "y_train_cat = pd.get_dummies(y_train).values\n",
        "y_test_cat = pd.get_dummies(y_test).values"
      ],
      "metadata": {
        "id": "ADJ7vmYJnMqy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model LSTM"
      ],
      "metadata": {
        "id": "nP3lafgu1Ckj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=100, input_length=max_len),\n",
        "    LSTM(128, return_sequences=True, kernel_regularizer='l2'),\n",
        "    Dropout(0.5),\n",
        "    LSTM(64, kernel_regularizer='l2'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2)\n",
        "]\n",
        "\n",
        "history = model_lstm.fit(\n",
        "    X_train_pad, y_train_cat,\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test_pad, y_test_cat),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "oss, accuracy_lstm = model_lstm.evaluate(X_test_pad, y_test_cat)\n",
        "print(\"\\nEvaluasi Model LSTM:\")\n",
        "print(f\"Accuracy: {accuracy_lstm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG9J-ovxpbGV",
        "outputId": "0cf703f9-f8b0-4237-c760-1518f0276301"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 369ms/step - accuracy: 0.8591 - loss: 1.7830 - val_accuracy: 0.8723 - val_loss: 0.4749 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 361ms/step - accuracy: 0.8701 - loss: 0.4833 - val_accuracy: 0.8723 - val_loss: 0.4612 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 351ms/step - accuracy: 0.8749 - loss: 0.4597 - val_accuracy: 0.8723 - val_loss: 0.4547 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 367ms/step - accuracy: 0.8673 - loss: 0.4745 - val_accuracy: 0.8723 - val_loss: 0.4547 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 365ms/step - accuracy: 0.8722 - loss: 0.4665 - val_accuracy: 0.8723 - val_loss: 0.4617 - learning_rate: 0.0010\n",
            "Epoch 6/15\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 370ms/step - accuracy: 0.8767 - loss: 0.4557 - val_accuracy: 0.8723 - val_loss: 0.4543 - learning_rate: 2.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 353ms/step - accuracy: 0.8649 - loss: 0.4778 - val_accuracy: 0.8723 - val_loss: 0.4551 - learning_rate: 2.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 359ms/step - accuracy: 0.8691 - loss: 0.4695 - val_accuracy: 0.8723 - val_loss: 0.4546 - learning_rate: 2.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 364ms/step - accuracy: 0.8726 - loss: 0.4574 - val_accuracy: 0.8723 - val_loss: 0.4544 - learning_rate: 4.0000e-05\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.8611 - loss: 0.4820\n",
            "\n",
            "Evaluasi Model LSTM:\n",
            "Accuracy: 0.8722500205039978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model LSTM yang telah dilatih menunjukkan akurasi sebesar 87.22% pada data uji. Meskipun akurasi tidak mencapai angka yang sangat tinggi, model ini masih cukup baik dalam mengklasifikasikan ulasan berdasarkan sentimen. Pada proses pelatihan, model menunjukkan penurunan kerugian (loss) yang stabil dari 1.78 di epoch pertama hingga 0.45 pada epoch terakhir, menunjukkan bahwa model mulai lebih akurat dalam memprediksi label sentimen seiring waktu. Selain itu, meskipun ada fluktuasi kecil pada akurasi dan loss antara epoch, model secara keseluruhan menunjukkan kinerja yang konsisten dan baik dalam mengenali pola dalam data ulasan."
      ],
      "metadata": {
        "id": "pHlhg-_l1gVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Kesimpulan Evaluasi Model Sentimen**\n",
        "\n",
        "Dari evaluasi tiga model yang diterapkan dalam proyek analisis sentimen terhadap ulasan aplikasi Disney+ Hotstar, diperoleh hasil yang cukup menarik:\n",
        "\n",
        "1. **Model SVM (Support Vector Machine)** memberikan hasil terbaik dengan akurasi **98.1%**. Model ini menunjukkan performa yang sangat baik dalam mengklasifikasikan ulasan dengan presisi tinggi pada kategori **positif** dan **netral**, namun sedikit kurang pada kategori **negatif**, dengan recall yang lebih rendah pada kelas tersebut.\n",
        "\n",
        "2. **Model Random Forest** menghasilkan akurasi **95.25%**. Meskipun akurasinya lebih rendah dibandingkan dengan SVM, model ini masih menunjukkan kinerja yang baik, dengan presisi yang solid untuk kategori **positif** dan **netral**, namun kurang optimal dalam mengidentifikasi ulasan **negatif** (recall rendah pada kategori ini).\n",
        "\n",
        "3. **Model LSTM (Long Short-Term Memory)**, meskipun lebih kompleks, menunjukkan akurasi **87.23%**. Model ini memiliki potensi yang lebih baik dalam memproses data teks yang lebih besar dan lebih beragam, namun akurasinya lebih rendah dibandingkan dengan dua model sebelumnya. Model LSTM cenderung lebih efektif dalam menangani urutan kata dan konteks dalam teks, meskipun memerlukan lebih banyak waktu dan sumber daya untuk pelatihan.\n",
        "\n",
        "Secara keseluruhan, **Model SVM** memberikan hasil terbaik untuk tugas klasifikasi sentimen pada ulasan pengguna Disney+ Hotstar, diikuti oleh **Random Forest** dan **LSTM** yang menunjukkan keunggulan masing-masing dalam hal teknik dan kompleksitas model."
      ],
      "metadata": {
        "id": "Y9VpMoti2cEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menyimpan dan Mengunduh Daftar Dependensi Python dalam File `requirements.txt`"
      ],
      "metadata": {
        "id": "DJpaW7201rnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n",
        "from google.colab import files\n",
        "files.download('requirements.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "e46ziwEcvhbm",
        "outputId": "ff4469cb-84e2-42ed-ea8a-686e7536df75"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7265a560-8383-43fa-90d8-81fa0f330029\", \"requirements.txt\", 12469)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}